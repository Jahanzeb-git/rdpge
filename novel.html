<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RDPGE-1: Runtime Dynamic Probabilistic Graph Execution</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.1/mermaid.min.js"></script>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap"
        rel="stylesheet">
    <style>
        :root {
            --primary: #0f172a;
            --accent: #3b82f6;
            --accent-light: #60a5fa;
            --success: #10b981;
            --warning: #f59e0b;
            --danger: #ef4444;
            --text: #334155;
            --text-light: #64748b;
            --bg: #ffffff;
            --bg-alt: #f8fafc;
            --border: #e2e8f0;
            --code-bg: #1e293b
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box
        }

        body {
            font-family: 'Inter', -apple-system, sans-serif;
            line-height: 1.7;
            color: var(--text);
            background: var(--bg);
            max-width: 920px;
            margin: 0 auto;
            padding: 60px 40px
        }

        header {
            text-align: center;
            margin-bottom: 60px;
            padding-bottom: 40px;
            border-bottom: 2px solid var(--border)
        }

        h1 {
            font-size: 2.75rem;
            color: var(--primary);
            letter-spacing: -0.03em;
            margin-bottom: 8px
        }

        .subtitle {
            font-size: 1.3rem;
            color: var(--text-light);
            font-weight: 400
        }

        .version {
            display: inline-block;
            background: var(--accent);
            color: white;
            padding: 4px 14px;
            border-radius: 20px;
            font-size: 0.8rem;
            margin-top: 16px
        }

        .abstract {
            background: linear-gradient(135deg, #eff6ff 0%, #f0fdf4 100%);
            border-left: 4px solid var(--accent);
            padding: 24px;
            border-radius: 0 8px 8px 0;
            margin: 40px 0
        }

        .abstract h3 {
            color: var(--accent);
            margin-bottom: 12px;
            font-size: 0.9rem;
            text-transform: uppercase;
            letter-spacing: 0.1em
        }

        h2 {
            font-size: 1.6rem;
            color: var(--primary);
            margin: 50px 0 20px;
            padding-bottom: 12px;
            border-bottom: 2px solid var(--accent)
        }

        h3 {
            font-size: 1.2rem;
            color: var(--primary);
            margin: 30px 0 15px
        }

        h4 {
            font-size: 1rem;
            color: var(--text);
            margin: 20px 0 10px
        }

        p {
            margin-bottom: 16px
        }

        .diagram-box {
            background: var(--bg-alt);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 30px;
            margin: 25px 0;
            text-align: center;
            overflow-x: auto
        }

        .diagram-box .caption {
            font-size: 0.85rem;
            color: var(--text-light);
            margin-top: 15px;
            font-style: italic
        }

        .diagram-box .caption strong {
            color: var(--primary)
        }

        pre {
            background: var(--code-bg);
            color: #e2e8f0;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin: 20px 0
        }

        code {
            font-family: 'JetBrains Mono', monospace
        }

        .ic {
            background: #f1f5f9;
            color: var(--primary);
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 0.9em
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 0.9rem
        }

        th,
        td {
            padding: 12px 16px;
            text-align: left;
            border-bottom: 1px solid var(--border)
        }

        th {
            background: var(--bg-alt);
            font-weight: 600;
            color: var(--primary)
        }

        tr:hover {
            background: var(--bg-alt)
        }

        .mg {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 20px;
            margin: 30px 0
        }

        .mc {
            background: var(--bg-alt);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 24px;
            text-align: center
        }

        .mc .v {
            font-size: 2.5rem;
            font-weight: 700;
            color: var(--accent)
        }

        .mc .l {
            color: var(--text-light);
            font-size: 0.9rem;
            margin-top: 8px
        }

        .mc.s .v {
            color: var(--success)
        }

        .mc.w .v {
            color: var(--warning)
        }

        .note {
            background: #fef3c7;
            border-left: 4px solid var(--warning);
            padding: 16px;
            border-radius: 0 8px 8px 0;
            margin: 20px 0
        }

        .note strong {
            color: #92400e
        }

        .cmp {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 25px 0
        }

        .cmp>div {
            padding: 20px;
            border-radius: 8px
        }

        .cmp .p {
            background: #fef2f2;
            border: 1px solid #fecaca
        }

        .cmp .sol {
            background: #f0fdf4;
            border: 1px solid #bbf7d0
        }

        .cmp h4 {
            margin-top: 0
        }

        ul,
        ol {
            margin: 16px 0 16px 24px
        }

        li {
            margin-bottom: 8px
        }

        .fs {
            display: flex;
            align-items: flex-start;
            margin: 15px 0
        }

        .fs .n {
            background: var(--accent);
            color: white;
            width: 28px;
            height: 28px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 600;
            font-size: 0.85rem;
            margin-right: 15px;
            flex-shrink: 0
        }

        .fs .c {
            flex: 1
        }

        .toc {
            background: var(--bg-alt);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0
        }

        .toc h3 {
            margin-top: 0
        }

        .toc ol {
            margin: 15px 0 0 20px
        }

        .toc a {
            color: var(--accent);
            text-decoration: none
        }

        .toc a:hover {
            text-decoration: underline
        }

        .key {
            background: #eff6ff;
            border: 1px solid #bfdbfe;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0
        }

        .key h4 {
            margin-top: 0;
            color: var(--accent)
        }

        @media print {
            body {
                padding: 20px
            }

            .diagram-box {
                break-inside: avoid
            }
        }
    </style>
</head>

<body>

    <header>
        <h1>RDPGE-1 Architecture</h1>
        <div class="subtitle">Runtime Dynamic Probabilistic Graph Execution</div>
        <div class="version">Version 2.0 ‚Äî February 2026</div>
    </header>

    <div class="abstract">
        <h3>Abstract</h3>
        <p>Current agentic AI architectures operate in two paradigms: <strong>ReAct</strong> (sequential, myopic,
            greedy) and <strong>Static Graphs</strong> (structured, deterministic, inflexible). Neither respects the
            probabilistic nature of Large Language Models. <strong>RDPGE-1</strong> introduces a third paradigm ‚Äî an
            <em>emergent graph architecture</em> where the execution graph is not pre-defined but dynamically
            constructed by the LLM during execution. Through <strong>Attention Anchors</strong>, <strong>Whole-Task
                Dynamic Edges</strong>, <strong>Context Blurring</strong>, and a <strong>Code-to-Object
                Interface</strong>, this architecture achieves superior dependency resolution, reduced contextual
            myopia, and unprecedented observability. Theoretical analysis projects 25-40% improvement in task accuracy
            and 60-80% reduction in context-related failures.
        </p>
    </div>

    <nav class="toc">
        <h3>Table of Contents</h3>
        <ol>
            <li><a href="#s1">Problem Statement & Motivation</a></li>
            <li><a href="#s2">Architecture Overview & Core Principles</a></li>
            <li><a href="#s3">The Emergent Graph Mechanism</a></li>
            <li><a href="#s4">Code-to-Object Interface</a></li>
            <li><a href="#s5">Context Management & Blurring</a></li>
            <li><a href="#s6">Graph Manifest & Distance Awareness</a></li>
            <li><a href="#s7">Graph Theory in RDPGE-1</a></li>
            <li><a href="#s8">Execution Flow</a></li>
            <li><a href="#s9">Observability System</a></li>
            <li><a href="#s10">Expected Performance Metrics</a></li>
            <li><a href="#s11">Conclusion</a></li>
        </ol>
    </nav>

    <!-- ============================================================ -->
    <section id="s1">
        <h2>1. Problem Statement & Motivation</h2>

        <h3>1.1 The ReAct Problem</h3>
        <p>The ReAct (Reasoning + Acting) pattern is the backbone of most modern agents. The agent thinks, acts,
            observes, and repeats. While elegant, it has fundamental flaws that surface in complex, multi-step coding
            tasks:</p>

        <div class="cmp">
            <div class="p">
                <h4>‚ùå Contextual Myopia</h4>
                <p>As context grows linearly, the LLM's attention becomes diluted. Information from early steps gets
                    "lost in the middle" (Liu et al., 2023). An agent working on Step 20 effectively "forgets" what it
                    did at Step 3.</p>
            </div>
            <div class="p">
                <h4>‚ùå Dependency Blindness</h4>
                <p>ReAct reasons one step at a time. It cannot see that fixing a bug in <code class="ic">auth.py</code>
                    (Step 15) breaks <code class="ic">routes.py</code> (which was written at Step 4 and is no longer in
                    active attention). This causes cascading bugs.</p>
            </div>
        </div>
        <div class="cmp">
            <div class="p">
                <h4>‚ùå Greedy Decision-Making</h4>
                <p>Each step optimizes locally without any lookahead. The agent takes the first plausible action,
                    leading to trial-and-error loops that waste tokens and reduce accuracy.</p>
            </div>
            <div class="p">
                <h4>‚ùå Flat History</h4>
                <p>ReAct produces a linear log ‚Äî a single, growing list of messages. There is no structure to
                    distinguish between independent tasks, dependent tasks, or completed tasks. This makes observability
                    and debugging extremely difficult.</p>
            </div>
        </div>

        <div class="diagram-box">
            <div class="mermaid">
                graph LR
                S1["Step 1<br />Read file"] --> S2["Step 2<br />Analyze"] --> S3["Step 3<br />Write code"] --> S4["..."]
                --> S15["Step 15<br />Fix bug"]
                S15 -.->|"Cannot see"| S3
                style S1 fill:#fecaca,stroke:#ef4444
                style S2 fill:#fecaca,stroke:#ef4444
                style S3 fill:#fecaca,stroke:#ef4444,stroke-width:3px
                style S15 fill:#dbeafe,stroke:#3b82f6,stroke-width:3px
                style S4 fill:#f1f5f9,stroke:#94a3b8
            </div>
            <div class="caption"><strong>Figure 1:</strong> ReAct's linear context. At Step 15, the agent cannot
                effectively "see" Step 3 because it's lost in the diluted middle context. There is no mechanism to
                selectively recall it.</div>
        </div>

        <h3>1.2 The Static Graph Problem (LangGraph)</h3>
        <p>LangGraph addresses some ReAct issues by introducing graph structure. However, the graph is
            <strong>pre-defined by the developer</strong>, not the LLM:
        </p>

        <table>
            <tr>
                <th>Aspect</th>
                <th>How LangGraph Works</th>
                <th>The Problem</th>
            </tr>
            <tr>
                <td>Edge Definition</td>
                <td>Hard-coded <code class="ic">if/else</code> conditionals</td>
                <td>Cannot adapt to discovered dependencies</td>
            </tr>
            <tr>
                <td>Graph Visibility</td>
                <td>Graph exists for developers only</td>
                <td>LLM sees a sequence of messages, not a graph</td>
            </tr>
            <tr>
                <td>Nature</td>
                <td>Deterministic control flow</td>
                <td>Conflicts with probabilistic LLM</td>
            </tr>
            <tr>
                <td>Flexibility</td>
                <td>Fixed topology at compile time</td>
                <td>Cannot add new connections at runtime</td>
            </tr>
        </table>

        <div class="key">
            <h4>The Core Insight</h4>
            <p>LangGraph's graph is a <strong>representation for humans</strong> ‚Äî a visual way for developers to
                understand control flow. But for the LLM, it is simply conditional execution. The LLM never "sees" or
                benefits from the graph structure. <strong>RDPGE-1 makes the graph visible and meaningful to the LLM
                    itself.</strong></p>
        </div>

        <h3>1.3 The RDPGE-1 Thesis</h3>
        <p>RDPGE-1 proposes a third paradigm based on three beliefs:</p>
        <ol>
            <li><strong>Trust the LLM:</strong> The LLM's probabilistic nature should be respected, not constrained.
                Decision-making safety is the LLM's responsibility; the framework handles only environmental security
                (sandbox, Docker isolation).</li>
            <li><strong>Emergent Structure:</strong> The execution graph should not be pre-defined. It should emerge
                naturally from the LLM's execution ‚Äî just as a human programmer's understanding of a codebase emerges as
                they work on it.</li>
            <li><strong>Selective Memory:</strong> Not all past context is equally relevant. The framework should
                provide mechanisms for the LLM to selectively recall relevant past work.</li>
        </ol>
    </section>

    <!-- ============================================================ -->
    <section id="s2">
        <h2>2. Architecture Overview & Core Principles</h2>

        <div class="diagram-box">
            <div class="mermaid">
                graph TB
                subgraph Framework["RDPGE-1 Framework"]
                CC["Context<br />Constructor"] --> GM["Graph<br />Manifest"]
                GM --> CO["Context<br />Orchestrator"]
                CO --> CE["Code<br />Executor"]
                CE --> TR["Tool<br />Router"]
                TR --> GSM["Graph State<br />Manager"]
                GSM --> CC
                end
                subgraph LLM["Large Language Model"]
                INF["Inference"]
                end
                U["User Request"] --> CC
                CO -->|"messages list"| INF
                INF -->|"Python code"| CE
                style Framework fill:#eff6ff,stroke:#3b82f6
                style LLM fill:#f0fdf4,stroke:#10b981
            </div>
            <div class="caption"><strong>Figure 2:</strong> High-level system architecture. The framework constructs
                context, sends it to the LLM, executes the returned code, runs tools, updates the graph state, and
                reconstructs context for the next turn.</div>
        </div>

        <h3>2.1 Core Principles</h3>
        <table>
            <tr>
                <th>Principle</th>
                <th>What It Means</th>
                <th>How It's Achieved</th>
            </tr>
            <tr>
                <td><strong>Probabilistic Trust</strong></td>
                <td>Let the LLM decide; enforce only environmental safety</td>
                <td>Sandboxed code execution in Docker</td>
            </tr>
            <tr>
                <td><strong>Emergent Structure</strong></td>
                <td>Graph topology emerges from execution</td>
                <td>LLM names nodes and declares edges</td>
            </tr>
            <tr>
                <td><strong>Attention Anchoring</strong></td>
                <td>Named nodes help the Transformer attend to relevant context</td>
                <td>Node IDs as prefixes in messages</td>
            </tr>
            <tr>
                <td><strong>Selective Context</strong></td>
                <td>Only relevant past context is fully visible</td>
                <td>Context blurring with edge restoration</td>
            </tr>
        </table>
    </section>

    <!-- ============================================================ -->
    <section id="s3">
        <h2>3. The Emergent Graph Mechanism</h2>

        <h3>3.1 Nodes: Attention Anchors</h3>
        <p>Every step the agent takes creates a <strong>node</strong>. Nodes follow the naming convention <code
                class="ic">node-{task}{step}</code>:</p>
        <ul>
            <li><strong>Task identifier:</strong> A single letter (a-z) representing a distinct task group. When the LLM
                determines the current work is unrelated to the previous task, it starts a new letter.</li>
            <li><strong>Step number:</strong> An incrementing number within the task (1, 2, 3...).</li>
            <li><strong>Example:</strong> <code class="ic">node-b3</code> means Task B, Step 3.</li>
        </ul>

        <p>These node names serve as <strong>Attention Anchors</strong> for the Transformer architecture. In
            self-attention, every token attends to every other token. By giving distinct, structured names to each step,
            we create "retrieval keys" that the model can latch onto, combating the "lost in the middle" effect.</p>

        <div class="diagram-box">
            <div class="mermaid">
                graph LR
                subgraph Messages["LLM Context Window (Messages List)"]
                M1["[node-a1] Read project..."]
                M2["[node-a2] Implement auth..."]
                M3["[node-a3] Write tests..."]
                M4["[node-b1] Setup database..."]
                M5["[node-b2] Create models..."]
                M6["[node-j1] Begin integration..."]
                M7["[node-j2] Current step..."]
                end
                M7 -.->|"Attention via<br />edge: node-a"| M1
                M7 -.->|"Attention"| M2
                M7 -.->|"Attention"| M3
                style M1 fill:#fef3c7,stroke:#f59e0b,stroke-width:2px
                style M2 fill:#fef3c7,stroke:#f59e0b,stroke-width:2px
                style M3 fill:#fef3c7,stroke:#f59e0b,stroke-width:2px
                style M7 fill:#dbeafe,stroke:#3b82f6,stroke-width:3px
            </div>
            <div class="caption"><strong>Figure 3:</strong> Attention anchors in action. When node-j2 declares an edge
                to "node-a", the Transformer's attention mechanism is guided toward ALL node-a messages, even if they
                are far back in the context window.</div>
        </div>

        <h3>3.2 Edges: Whole-Task Dynamic Dependencies</h3>
        <p>This is where RDPGE-1 fundamentally differs from both ReAct and LangGraph. The LLM can <strong>dynamically
                declare dependencies</strong> between tasks at runtime.</p>

        <div class="key">
            <h4>Critical Design Decision: Whole-Task Edges</h4>
            <p>Dynamic edges connect to an <strong>entire task</strong>, not a specific step. When the agent at <code
                    class="ic">node-j2</code> declares <code class="ic">"edge": "node-a"</code>, it means: <em>"I need
                    context from ALL steps of Task A."</em> This is simpler for the LLM (it doesn't need to remember
                specific step numbers) and ensures complete dependency resolution.</p>
        </div>

        <div class="diagram-box">
            <div class="mermaid">
                graph LR
                subgraph TA["Task A: Authentication"]
                A1((a1)) --> A2((a2)) --> A3((a3))
                end
                subgraph TB["Task B: Database"]
                B1((b1)) --> B2((b2))
                end
                subgraph TJ["Task J: Integration"]
                J1((j1)) --> J2((j2))
                end
                TJ -.->|"edge: node-a<br />(whole task)"| TA
                style A1 fill:#93c5fd,stroke:#2563eb,stroke-width:2px
                style A2 fill:#93c5fd,stroke:#2563eb,stroke-width:2px
                style A3 fill:#93c5fd,stroke:#2563eb,stroke-width:2px
                style B1 fill:#dcfce7,stroke:#10b981
                style B2 fill:#dcfce7,stroke:#10b981
                style J1 fill:#f3e8ff,stroke:#9333ea
                style J2 fill:#c4b5fd,stroke:#9333ea,stroke-width:3px
            </div>
            <div class="caption"><strong>Figure 4:</strong> The Emergent Graph with whole-task edges. Node-j2 creates an
                edge to Task A as a whole ‚Äî restoring tool outputs from ALL of Task A's steps (a1, a2, a3).</div>
        </div>

        <p><strong>How the LLM performs this:</strong> The LLM simply sets <code class="ic">"edge": "node-a"</code> in
            its action dictionary. The framework then restores ALL blurred tool outputs from every step of Task A. The
            LLM can also create multiple edges in subsequent steps (e.g., <code class="ic">node-j ‚Üí node-a</code>, then
            later <code class="ic">node-j ‚Üí node-b</code>).</p>

        <h3>3.3 Two Types of Edges</h3>
        <table>
            <tr>
                <th>Edge Type</th>
                <th>How It's Created</th>
                <th>What It Connects</th>
                <th>Example</th>
            </tr>
            <tr>
                <td><strong>Sequential Edge</strong></td>
                <td>Implicit (same task letter, incrementing step)</td>
                <td>Step to next step within a task</td>
                <td>node-a1 ‚Üí node-a2 ‚Üí node-a3</td>
            </tr>
            <tr>
                <td><strong>Dynamic Edge</strong></td>
                <td>Explicit (LLM sets <code class="ic">"edge"</code> in action dict)</td>
                <td>Current task to any other entire task</td>
                <td>node-j ‚Üí node-a (whole task)</td>
            </tr>
        </table>
    </section>

    <!-- ============================================================ -->
    <section id="s4">
        <h2>4. Code-to-Object Interface</h2>

        <h3>4.1 Why Code Instead of JSON?</h3>
        <p>Most agents use JSON schemas or function-calling APIs. RDPGE-1 replaces these with
            <strong>Python-as-Schema</strong>: the LLM outputs executable Python code that must define an <code
                class="ic">action</code> dictionary variable.
        </p>

        <div class="cmp">
            <div class="p">
                <h4>Traditional JSON Mode</h4>
                <ul>
                    <li>Strict formatting (one syntax error = failure)</li>
                    <li>No space for reasoning</li>
                    <li>String escaping issues</li>
                    <li>Research shows 10-15% accuracy drop</li>
                </ul>
            </div>
            <div class="sol">
                <h4>Code-to-Object (RDPGE-1)</h4>
                <ul>
                    <li>Natural code generation (LLMs excel at this)</li>
                    <li>Comments serve as reasoning trace</li>
                    <li>Variables prevent escaping issues</li>
                    <li>Full Python flexibility</li>
                </ul>
            </div>
        </div>

        <h3>4.2 The Action Dictionary</h3>
        <table>
            <tr>
                <th>Field</th>
                <th>Type</th>
                <th>Required</th>
                <th>Description</th>
            </tr>
            <tr>
                <td><code>node</code></td>
                <td>string</td>
                <td>Yes</td>
                <td>Current step ID: <code class="ic">"node-a3"</code></td>
            </tr>
            <tr>
                <td><code>edge</code></td>
                <td>string | None</td>
                <td>Yes</td>
                <td>Whole-task edge: <code class="ic">"node-a"</code> or <code class="ic">None</code></td>
            </tr>
            <tr>
                <td><code>reason</code></td>
                <td>string</td>
                <td>Yes</td>
                <td>User-facing message explaining what the agent is doing. This is shown in the chat UI.</td>
            </tr>
            <tr>
                <td><code>tool_call</code></td>
                <td>dict | None</td>
                <td>No</td>
                <td>Tool invocation: <code class="ic">{"name": ..., "args": {...}}</code></td>
            </tr>
        </table>

        <div class="key">
            <h4>Dual Reasoning: Comments vs. Reason Field</h4>
            <p>The LLM has two channels for expressing its thinking:</p>
            <ul>
                <li><strong>Comments (<code class="ic">#</code>):</strong> Internal reasoning ‚Äî private scratchpad for
                    the LLM. Only visible in the observability graph trace. Used for technical analysis, referencing
                    past nodes, and planning.</li>
                <li><strong><code class="ic">reason</code> field:</strong> User-facing message ‚Äî shown directly to the
                    user in the chat interface. Should be clear, friendly, and explain what the agent is doing and why.
                </li>
            </ul>
        </div>

        <h3>4.3 Example: LLM Code Output</h3>
        <pre><code class="python"># [node-j2] Integration: Verify auth token format
# I need to check the JWT implementation from Task A.
# The user asked for OAuth integration, so I need to see
# what's already there. I suspect they're using PyJWT based on
# the requirements.txt I saw in step a1.

file_path = "src/auth.py"

print(f"DEBUG: Reading {file_path} to verify JWT format")

action = {
    "node": "node-j2",
    "edge": "node-a",
    "reason": "Let me read your authentication module to understand the current JWT setup before integrating OAuth.",
    "tool_call": {
        "name": "read_file",
        "args": {"path": file_path}
    }
}</code></pre>

        <p>Notice the separation: <strong>comments</strong> contain detailed technical reasoning (references to step a1,
            hypothesis about PyJWT). The <strong>reason field</strong> contains a clear, friendly message for the user.
        </p>

        <h3>4.4 How Extraction Works</h3>
        <p>The framework executes the LLM's code using Python's <code class="ic">exec()</code> with isolated namespaces,
            then extracts the <code class="ic">action</code> variable from the local namespace. Console output (from
            <code class="ic">print()</code>) is captured separately. The LLM is free to write any valid Python ‚Äî helper
            functions, loops, conditionals ‚Äî as long as the code defines the <code class="ic">action</code> dictionary.
        </p>

        <div class="diagram-box">
            <div class="mermaid">
                graph LR
                A["LLM generates<br />Python code"] --> B["Framework runs<br />exec() in sandbox"]
                B --> C["Extract 'action'<br />from locals()"]
                B --> D["Capture stdout<br />as console output"]
                C --> E["Validate action<br />schema"]
                E --> F["Execute tool_call<br />if present"]
                style A fill:#dbeafe,stroke:#3b82f6
                style F fill:#dcfce7,stroke:#10b981
            </div>
            <div class="caption"><strong>Figure 5:</strong> Code-to-Object extraction pipeline. The only constraint on
                the LLM is that the code must define an <code>action</code> dictionary.</div>
        </div>
    </section>

    <!-- ============================================================ -->
    <section id="s5">
        <h2>5. Context Management & Blurring</h2>

        <h3>5.1 The Problem: Tool Outputs Are Heavy</h3>
        <p>Tool outputs ‚Äî file contents, command results, API responses ‚Äî consume the majority of tokens in an agent's
            context. A single <code class="ic">read_file</code> call can produce hundreds or thousands of tokens. As the
            agent works, inactive tool outputs accumulate, diluting attention.</p>

        <h3>5.2 The Solution: Selective Blurring</h3>
        <p>RDPGE-1 removes tool outputs from <strong>inactive nodes</strong> while preserving the structural information
            (code and console output). Tool outputs are restored when the LLM explicitly declares an edge.</p>

        <h3>5.3 What Is Kept vs. Removed</h3>
        <table>
            <tr>
                <th>Node State</th>
                <th>LLM Code</th>
                <th>Console Output</th>
                <th>Tool Output</th>
            </tr>
            <tr>
                <td>‚úÖ <strong>Active</strong> (current node)</td>
                <td>‚úÖ Full</td>
                <td>‚úÖ Full</td>
                <td>‚úÖ Full</td>
            </tr>
            <tr>
                <td>üîó <strong>Restored</strong> (via edge)</td>
                <td>‚úÖ Full</td>
                <td>‚úÖ Full</td>
                <td>‚úÖ Restored</td>
            </tr>
            <tr>
                <td>üîí <strong>Inactive</strong> (blurred)</td>
                <td>‚úÖ Full</td>
                <td>‚úÖ Full</td>
                <td>‚ùå Removed</td>
            </tr>
        </table>

        <h3>5.4 Why Keep Code and Console?</h3>
        <ul>
            <li><strong>Code is kept</strong> because it contains both <em>reasoning</em> (comments) and <em>action
                    structure</em> (what tool was called, what file was affected). This is "structural memory."</li>
            <li><strong>Console output is kept</strong> because it's typically lightweight (a few debug prints) and
                shows intermediate computations.</li>
            <li><strong>Tool output is removed</strong> because it's the heavy payload. A file's content, a command's
                result ‚Äî these are large and only relevant when actively working on that task.</li>
        </ul>

        <div class="diagram-box">
            <div class="mermaid">
                graph TB
                subgraph Active["‚úÖ Active: node-j2"]
                AC["Code ‚úì"] --- ACO["Console ‚úì"] --- ATO["Tool Output ‚úì"]
                end
                subgraph Restored["üîó Restored: Task A (via edge)"]
                RC["Code ‚úì"] --- RCO["Console ‚úì"] --- RTO["Tool Output ‚úì"]
                end
                subgraph Blurred["üîí Inactive: Task B"]
                BC["Code ‚úì"] --- BCO["Console ‚úì"] --- BTO["Tool Output ‚úó"]
                end
                style Active fill:#dbeafe,stroke:#3b82f6,stroke-width:2px
                style Restored fill:#fef3c7,stroke:#f59e0b,stroke-width:2px
                style Blurred fill:#f1f5f9,stroke:#94a3b8
                style BTO fill:#fecaca,stroke:#ef4444
            </div>
            <div class="caption"><strong>Figure 6:</strong> Context visibility by node state. Active and edge-restored
                nodes have full context. Inactive nodes retain code and console only ‚Äî tool outputs are blurred until an
                edge restores them.</div>
        </div>

        <h3>5.5 Large File Handling</h3>
        <p>For files that would consume too many tokens, the LLM can request specific line ranges:</p>
        <pre><code class="python">action = {
    "node": "node-a2",
    "edge": None,
    "tool_call": {
        "name": "read_file",
        "args": {
            "path": "src/large_module.py",
            "start_line": 150,
            "end_line": 250
        }
    }
}</code></pre>
        <p>The system prompt includes a codebase snapshot with file sizes so the LLM can make informed decisions:</p>
        <pre><code>CODEBASE SNAPSHOT:
src/
‚îú‚îÄ‚îÄ app.py (45 lines)
‚îú‚îÄ‚îÄ auth.py (120 lines)
‚îú‚îÄ‚îÄ large_module.py (850 lines)  ‚Üê Use line ranges
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ user.py (65 lines)</code></pre>
    </section>

    <!-- ============================================================ -->
    <section id="s6">
        <h2>6. Graph Manifest & Distance Awareness</h2>

        <h3>6.1 The Graph Manifest</h3>
        <p>The system prompt includes a constantly-updated <strong>Graph Manifest</strong> that gives the LLM a
            bird's-eye view of the entire execution. This solves the "discovery problem" ‚Äî how does the LLM know which
            tasks exist and which it can connect to?</p>

        <h3>6.2 Distance Awareness</h3>
        <p>A critical enhancement: the manifest includes <strong>distance information</strong> ‚Äî how many steps ago each
            task was last active. This gives the LLM a sense of how "far back" each task is in the linear history,
            regardless of edge connections.</p>

        <pre><code>## RDPGE GRAPH MANIFEST
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Active Node: node-j2
Active Task: J (Integration)

Task Map (distance = steps since last active):
  Task A (Auth):     12 steps ago | 3 references | 3 steps total | ‚ö†Ô∏è CRITICAL
  Task B (Database):  5 steps ago | 0 references | 2 steps total
  Task C (API):       3 steps ago | 1 reference  | 4 steps total
  Task J (Current):   active      | 0 references | 2 steps total

You may create an edge to any task by setting "edge": "node-x"
This will restore that task's full context (all tool outputs).</code></pre>

        <h3>6.3 Why Distance Matters</h3>
        <p>Distance is not a property of a node ‚Äî it changes depending on the current position. That's why it lives in
            the manifest (which updates every turn), not in the node name. Distance tells the LLM:</p>
        <ul>
            <li><strong>Low distance</strong> (2-3 steps ago): Context is probably still fresh, might not need edge</li>
            <li><strong>High distance</strong> (15+ steps ago): Context is definitely diluted, edge would be valuable
            </li>
        </ul>
    </section>

    <!-- ============================================================ -->
    <section id="s7">
        <h2>7. Graph Theory in RDPGE-1</h2>

        <p>Because RDPGE-1 produces a <strong>real mathematical graph</strong> during execution, we can apply graph
            theory to enhance the agent's intelligence.</p>

        <h3>7.1 Graph Classification</h3>
        <p>The RDPGE-1 execution graph is a <strong>Directed Acyclic Graph (DAG)</strong>:</p>
        <ul>
            <li><strong>Directed:</strong> Edges have direction (steps flow forward, edges point to dependencies)</li>
            <li><strong>Acyclic:</strong> No loops ‚Äî execution moves forward</li>
        </ul>

        <h3>7.2 In-Degree: Measuring Task Importance</h3>
        <p>The <strong>in-degree</strong> of a task is the number of other tasks that have created edges pointing to it.
            A high in-degree means many other tasks depend on this task's output.</p>

        <div class="diagram-box">
            <div class="mermaid">
                graph LR
                subgraph TA["Task A<br />In-degree: 3 ‚ö†Ô∏è"]
                A1((a1)) --> A2((a2)) --> A3((a3))
                end
                subgraph TB["Task B<br />In-degree: 0"]
                B1((b1)) --> B2((b2))
                end
                subgraph TC["Task C<br />In-degree: 1"]
                C1((c1)) --> C2((c2))
                end
                subgraph TD["Task D"]
                D1((d1))
                end
                subgraph TJ["Task J"]
                J1((j1)) --> J2((j2))
                end
                TC -.->|edge| TA
                TD -.->|edge| TA
                TJ -.->|edge| TA
                TJ -.->|edge| TC
                style A1 fill:#fecaca,stroke:#ef4444,stroke-width:2px
                style A2 fill:#fecaca,stroke:#ef4444,stroke-width:2px
                style A3 fill:#fecaca,stroke:#ef4444,stroke-width:2px
                style B1 fill:#dcfce7,stroke:#10b981
                style B2 fill:#dcfce7,stroke:#10b981
            </div>
            <div class="caption"><strong>Figure 7:</strong> In-degree visualization. Task A has in-degree 3 (referenced
                by Tasks C, D, and J) making it critical. Task B has in-degree 0 ‚Äî completely isolated.</div>
        </div>

        <div class="key">
            <h4>Practical Application</h4>
            <p>In-degree is surfaced in the Graph Manifest as "references." When the LLM sees <code
                    class="ic">Task A: 3 references | ‚ö†Ô∏è CRITICAL</code>, it understands that modifying Task A's outputs
                would affect many downstream tasks. This promotes careful, dependency-aware reasoning.</p>
        </div>

        <h3>7.3 Dependency Distance</h3>
        <p>The dependency distance measures how many steps separate two tasks in linear execution history. This is
            surfaced as "steps ago" in the Graph Manifest, helping the LLM gauge context freshness.</p>

        <h3>7.4 Future Graph Enhancements</h3>
        <p>The DAG structure opens doors for future algorithmic enhancements:</p>
        <table>
            <tr>
                <th>Algorithm</th>
                <th>Potential Use</th>
                <th>Status</th>
            </tr>
            <tr>
                <td>Topological Sort</td>
                <td>True execution order for replay/visualization</td>
                <td>Future</td>
            </tr>
            <tr>
                <td>Connected Components</td>
                <td>Identify independent vs dependent task groups</td>
                <td>Future</td>
            </tr>
            <tr>
                <td>Shortest Path</td>
                <td>Measure reasoning distance between tasks</td>
                <td>Future</td>
            </tr>
            <tr>
                <td>Betweenness Centrality</td>
                <td>Find bridge tasks connecting task groups</td>
                <td>Future</td>
            </tr>
        </table>
    </section>

    <!-- ============================================================ -->
    <section id="s8">
        <h2>8. Execution Flow</h2>

        <h3>8.1 Turn-by-Turn Flow</h3>
        <div class="fs">
            <div class="n">0</div>
            <div class="c"><strong>Initialize:</strong> Create GraphState; build initial messages (system prompt +
                manifest + user request)</div>
        </div>
        <div class="fs">
            <div class="n">1</div>
            <div class="c"><strong>LLM Inference:</strong> Send messages to LLM via API; receive Python code in response
            </div>
        </div>
        <div class="fs">
            <div class="n">2</div>
            <div class="c"><strong>Code Extraction:</strong> Parse Python code from triple-backtick block</div>
        </div>
        <div class="fs">
            <div class="n">3</div>
            <div class="c"><strong>Code Execution:</strong> Run code in sandbox; extract <code class="ic">action</code>
                dict; capture console output</div>
        </div>
        <div class="fs">
            <div class="n">4</div>
            <div class="c"><strong>Tool Execution:</strong> If <code class="ic">tool_call</code> present, execute tool
                and capture output</div>
        </div>
        <div class="fs">
            <div class="n">5</div>
            <div class="c"><strong>Graph Update:</strong> Update manifest, apply edge if declared, apply blurring to
                inactive nodes</div>
        </div>
        <div class="fs">
            <div class="n">6</div>
            <div class="c"><strong>Context Reconstruction:</strong> Build next messages list with blurred history +
                current result</div>
        </div>
        <div class="fs">
            <div class="n">7</div>
            <div class="c"><strong>Loop:</strong> Return to step 1 until task complete or max steps reached</div>
        </div>

        <h3>8.2 Sequence Diagram</h3>
        <div class="diagram-box">
            <div class="mermaid">
                sequenceDiagram
                participant U as User
                participant F as Framework
                participant L as LLM
                participant S as Sandbox
                participant T as Tools

                U->>F: Task Request
                F->>F: Build initial context (system + manifest + request)
                loop Each Step
                F->>L: messages list
                L->>F: Python code (in triple backticks)
                F->>S: Execute code
                S->>F: action dict + console output
                F->>T: Execute tool_call (if any)
                T->>F: Tool output
                F->>F: Update graph state, apply blurring
                F->>F: Reconstruct context for next turn
                end
                F->>U: Final result + execution graph
            </div>
            <div class="caption"><strong>Figure 8:</strong> Complete execution sequence. Each turn: inference ‚Üí execute
                ‚Üí tool ‚Üí update ‚Üí reconstruct.</div>
        </div>

        <h3>8.3 Execution Result Format (Fed Back to LLM)</h3>
        <p>After each step, the following is included in the next messages list:</p>
        <pre><code>=== EXECUTION RESULT FOR [node-a2] ===

## YOUR CODE:
```python
# [node-a2] Analyzing project structure
# The project seems small, I'll read the main app file
action = {"node": "node-a2", "edge": None,
          "reason": "Let me take a look at your main application file to understand the structure.",
          "tool_call": {"name": "read_file", "args": {"path": "src/app.py"}}}
```

## CONSOLE OUTPUT:
(none)

## TOOL RESULT:
from flask import Flask
app = Flask(__name__)
...

=== END EXECUTION RESULT ===</code></pre>
    </section>

    <!-- ============================================================ -->
    <section id="s9">
        <h2>9. Observability System</h2>

        <p>RDPGE-1's graph structure, combined with the dual-reasoning design (comments + reason field), provides
            <strong>three distinct layers of transparency</strong> ‚Äî a major advantage over ReAct's flat logs.
        </p>

        <h3>9.1 Three-Layer Transparency Model</h3>

        <div class="diagram-box">
            <div class="mermaid">
                graph TB
                subgraph L1["Layer 1: User Interface"]
                R["reason field<br />'Let me read your auth module...'"]
                TC["Tool activity indicator<br />'üìÑ Reading src/auth.py...'"]
                end
                subgraph L2["Layer 2: Developer Dashboard"]
                CM["Comments (internal reasoning)<br />'I suspect they use PyJWT based on step a1...'"]
                UM["User message (reason field)"]
                TL["Tool call details"]
                ED["Edge declarations"]
                end
                subgraph L3["Layer 3: Full Execution Trace"]
                FC["Complete code"]
                CO["Console output"]
                TO["Tool output"]
                GS["Graph connections"]
                end
                style L1 fill:#dbeafe,stroke:#3b82f6,stroke-width:2px
                style L2 fill:#fef3c7,stroke:#f59e0b,stroke-width:2px
                style L3 fill:#f0fdf4,stroke:#10b981,stroke-width:2px
            </div>
            <div class="caption"><strong>Figure 9:</strong> Three-layer transparency. Layer 1 is what the user sees
                (reason field). Layer 2 is the developer/observability view (comments + metadata). Layer 3 is the
                complete trace for deep debugging.</div>
        </div>

        <table>
            <tr>
                <th>Layer</th>
                <th>Audience</th>
                <th>Content</th>
                <th>Source</th>
            </tr>
            <tr>
                <td><strong>Layer 1: User UI</strong></td>
                <td>End user</td>
                <td>Friendly explanation of what agent is doing</td>
                <td><code class="ic">reason</code> field in action dict</td>
            </tr>
            <tr>
                <td><strong>Layer 2: Developer Dashboard</strong></td>
                <td>Developer / Observer</td>
                <td>Internal reasoning, tool calls, edges, node metadata</td>
                <td>Python comments + action dict metadata</td>
            </tr>
            <tr>
                <td><strong>Layer 3: Full Trace</strong></td>
                <td>Deep debugging</td>
                <td>Complete code, console output, tool outputs, graph</td>
                <td>Everything stored per node</td>
            </tr>
        </table>

        <p>Most agents only provide Layer 1 (a chat log). RDPGE-1's architecture naturally produces all three layers
            without any additional effort ‚Äî the code-to-object interface inherently separates internal reasoning
            (comments) from user communication (reason field).</p>

        <h3>9.2 Graph Export</h3>
        <p>The complete execution graph is exportable as JSON, enabling interactive visualization:</p>

        <div class="cmp">
            <div class="sol">
                <h4>üîç Zoomable Graph View</h4>
                <p>Users can see the full graph, click any node to inspect the LLM's internal reasoning (comments),
                    user-facing message (reason), and tool results. Dynamic edges are shown as connections between
                    tasks.</p>
            </div>
            <div class="sol">
                <h4>üìä Downloadable Trace</h4>
                <p>The JSON graph file captures the entire session. Each node stores: code, reasoning, user message,
                    tool output, edges, and timestamps. This enables post-mortem analysis and reproducibility.</p>
            </div>
        </div>

        <h3>9.3 Comparison with Existing Approaches</h3>
        <table>
            <tr>
                <th>Feature</th>
                <th>ReAct</th>
                <th>LangGraph</th>
                <th>RDPGE-1</th>
            </tr>
            <tr>
                <td>Execution trace</td>
                <td>Linear log</td>
                <td>Static graph + log</td>
                <td>Dynamic emergent graph</td>
            </tr>
            <tr>
                <td>Reasoning visibility</td>
                <td>Buried in long text</td>
                <td>Per-node (pre-defined)</td>
                <td>Per-node (emergent, from comments)</td>
            </tr>
            <tr>
                <td>Dependency tracking</td>
                <td>None</td>
                <td>Pre-defined edges</td>
                <td>Dynamic edges (runtime)</td>
            </tr>
            <tr>
                <td>Debug experience</td>
                <td>Read thousands of lines</td>
                <td>Inspect pre-defined nodes</td>
                <td>Click any node, see reasoning + action</td>
            </tr>
        </table>
    </section>

    <!-- ============================================================ -->
    <section id="s10">
        <h2>10. Expected Performance Metrics</h2>
        <p>Based on theoretical analysis and comparison with documented ReAct limitations:</p>

        <div class="mg">
            <div class="mc s">
                <div class="v">+25-40%</div>
                <div class="l">Task Completion Accuracy</div>
            </div>
            <div class="mc s">
                <div class="v">-60-80%</div>
                <div class="l">Context-Related Failures</div>
            </div>
            <div class="mc s">
                <div class="v">+50-70%</div>
                <div class="l">Dependency Resolution</div>
            </div>
            <div class="mc w">
                <div class="v">-30-50%</div>
                <div class="l">Token Usage (via Blurring)</div>
            </div>
        </div>

        <table>
            <tr>
                <th>Metric</th>
                <th>ReAct Baseline</th>
                <th>RDPGE-1 Target</th>
                <th>Mechanism</th>
            </tr>
            <tr>
                <td>Myopia Reduction</td>
                <td>High in long tasks</td>
                <td>70-85% reduction</td>
                <td>Attention anchors + edge restoration</td>
            </tr>
            <tr>
                <td>Hallucination Rate</td>
                <td>~15-25% (complex tasks)</td>
                <td>~5-10%</td>
                <td>Code-to-Object validation + structured output</td>
            </tr>
            <tr>
                <td>Dependency Errors</td>
                <td>Common in multi-file</td>
                <td>Rare</td>
                <td>Explicit edge declaration + in-degree awareness</td>
            </tr>
            <tr>
                <td>Trial-and-Error Loops</td>
                <td>Frequent</td>
                <td>Minimal</td>
                <td>Graph manifest provides global task awareness</td>
            </tr>
        </table>

        <div class="note"><strong>Note:</strong> These metrics are theoretical targets based on architectural analysis.
            Empirical validation through controlled experiments is required.</div>
    </section>

    <!-- ============================================================ -->
    <section id="s11">
        <h2>11. Conclusion</h2>

        <h3>11.1 Key Contributions</h3>
        <ol>
            <li><strong>Emergent Graph Execution:</strong> Graph topology emerges from LLM execution rather than being
                pre-defined</li>
            <li><strong>Attention Anchors:</strong> Named nodes serve as retrieval keys for Transformer attention</li>
            <li><strong>Whole-Task Dynamic Edges:</strong> LLM-driven dependency declaration restoring entire task
                contexts on demand</li>
            <li><strong>Code-to-Object Interface:</strong> Python-native output with scratchpad reasoning via comments
            </li>
            <li><strong>Context Blurring:</strong> Selective removal of heavy payloads from inactive tasks while
                preserving structural memory</li>
            <li><strong>Distance-Aware Manifest:</strong> Global task map with dependency counts and recency information
            </li>
            <li><strong>Graph-Powered Observability:</strong> Zoomable execution graphs with per-node reasoning traces
            </li>
        </ol>

        <h3>11.2 Architectural Comparison</h3>
        <table>
            <tr>
                <th>Dimension</th>
                <th>ReAct</th>
                <th>LangGraph</th>
                <th>RDPGE-1</th>
            </tr>
            <tr>
                <td>Graph</td>
                <td>None (flat list)</td>
                <td>Static, pre-defined</td>
                <td>Dynamic, emergent</td>
            </tr>
            <tr>
                <td>Context</td>
                <td>Linear, growing</td>
                <td>Per-node (fixed)</td>
                <td>Blurred + edge-restored</td>
            </tr>
            <tr>
                <td>Dependencies</td>
                <td>Implicit (lost)</td>
                <td>Hard-coded edges</td>
                <td>Dynamic whole-task edges</td>
            </tr>
            <tr>
                <td>LLM Interface</td>
                <td>JSON / function calls</td>
                <td>JSON / function calls</td>
                <td>Code-to-Object (Python)</td>
            </tr>
            <tr>
                <td>LLM Nature</td>
                <td>Ignored</td>
                <td>Constrained</td>
                <td>Respected (probabilistic trust)</td>
            </tr>
            <tr>
                <td>Observability</td>
                <td>Linear logs</td>
                <td>Static graph view</td>
                <td>Interactive emergent graph</td>
            </tr>
        </table>

        <h3>11.3 Future Work</h3>
        <ul>
            <li>Empirical validation across diverse coding benchmarks</li>
            <li>Z-Score probabilistic feedback loop (using logprobs)</li>
            <li>Advanced graph algorithms (connected components, topological sort)</li>
            <li>Multi-agent extensions with shared graph state</li>
            <li>Graduated context blurring using graph metrics</li>
        </ul>
    </section>

    <footer
        style="margin-top:60px;padding-top:30px;border-top:2px solid var(--border);text-align:center;color:var(--text-light)">
        <p><strong>RDPGE-1</strong> ‚Äî A Novel Contribution to Agentic AI Architecture</p>
        <p style="font-size:0.85rem">Jahanzeb Ahmed ‚Ä¢ February 2026</p>
    </footer>

    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'base', themeVariables: { primaryColor: '#dbeafe', primaryTextColor: '#1e40af', primaryBorderColor: '#3b82f6', lineColor: '#64748b', secondaryColor: '#f0fdf4', tertiaryColor: '#f8fafc' } });
    </script>
</body>

</html>